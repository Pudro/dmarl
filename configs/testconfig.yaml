env:
  env_id: "custom_battle"
  log_dir: "./logs/iql_test_battle/"
  # model_dir_load: "./models/iql_test_battle/"
  # model_dir_save: "./models/iql_test_battle/"
  project_name: "MAgent2"
  logger: "tensorboard"  # Choices: tensorboard, wandb.
  wandb_user_name: "your_user_name"
  render_mode: 'human' # Choices: 'human', 'rgb_array'.
  test_mode: False
  device: "cpu"
  minimap_mode: False
  max_cycles: 1000 # number of env.steps in an episode
  extra_features: False
  map_size: 20
  seed: 1
  running_steps: 1000000
  render_episode_period: 1

agents:
-
  model_dir_load: "models/iql_test_battle/2024-3-19_14:31:13/red"
  model_dir_save: "./models/iql_test_battle/"
  load_policy_only: False
  reset_optimizer: False
  algorithm: "IQL"  # the learning algorithms_marl
  side_name: "red"
  layer_type: "Linear"
  hidden_layers: [64, ]
  activation: "ReLU"

  buffer_size: 20000
  batch_size: 32
  learning_start: 50
  learning_rate: 0.001
  gamma: 0.95  # discount factor
  double_q: True  # use double q learning
  tau: 0.005

  start_greedy: 0.5
  end_greedy: 0.05
  start_training: 50  # start training after n episodes
  train_per_step: False  # True: train model per step; False: train model per episode.
  train_period: 10
  target_network_train_period: 20
  sync_period: 100

  use_grad_clip: False
  grad_clip_norm: 0.5

  eval_interval: 100000
  test_episode: 5

-
  model_dir_load: "models/iql_test_battle/2024-3-19_14:31:13/blue"
  model_dir_save: "./models/iql_test_battle/"
  load_policy_only: False
  reset_optimizer: False
  algorithm: "IQL"  # the learning algorithms_marl
  side_name: "blue"
  layer_type: "Linear"
  hidden_layers: [16, 32]
  activation: "ReLU"

  buffer_size: 20000
  batch_size: 32
  learning_start: 50
  learning_rate: 0.001
  gamma: 0.95  # discount factor
  double_q: True  # use double q learning
  tau: 0.005

  start_greedy: 0.5
  end_greedy: 0.05
  start_training: 50  # start training after n episodes
  train_per_step: False  # True: train model per step; False: train model per episode.
  train_period: 10
  target_network_train_period: 20
  sync_period: 100

  use_grad_clip: False
  grad_clip_norm: 0.5

  eval_interval: 100000
  test_episode: 5
